{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q inference-gpu[yolo-world]==0.9.12rc1\n",
    "!pip install -q supervision==0.19.0rc3\n",
    "!pip install fastapi uvicorn\n",
    "!pip install python-multipart\n",
    "!pip install pyngrok\n",
    "!pip install deepl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import supervision as sv\n",
    "from tqdm import tqdm\n",
    "from inference.models.yolo_world.yolo_world import YOLOWorld\n",
    "from fastapi import FastAPI, Request, HTTPException\n",
    "from starlette.middleware.base import BaseHTTPMiddleware\n",
    "import base64\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from pyngrok import ngrok\n",
    "import nest_asyncio\n",
    "import os\n",
    "import deepl\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# FastAPI 앱 설정\n",
    "app = FastAPI()\n",
    "\n",
    "# Bounding Box Annotator 설정\n",
    "BOUNDING_BOX_ANNOTATOR = sv.BoundingBoxAnnotator(thickness=2)\n",
    "LABEL_ANNOTATOR = sv.LabelAnnotator(text_thickness=2, text_scale=1, text_color=sv.Color.BLACK)\n",
    "\n",
    "# YOLO-World 모델 로드\n",
    "model = YOLOWorld(model_id=\"yolo_world/l\")\n",
    "\n",
    "@app.middleware(\"http\")\n",
    "async def add_ngrok_headers(request: Request, call_next):\n",
    "    response = await call_next(request)\n",
    "    response.headers[\"ngrok-skip-browser-warning\"] = \"any_value\"\n",
    "    return response\n",
    "\n",
    "@app.post(\"/detect_objects\")\n",
    "async def detect_objects(request: Request):\n",
    "    data = await request.json()\n",
    "    video_url = data[\"video_url\"]\n",
    "    object_name = data[\"object_name\"]\n",
    "    print(f\"Object Name: {object_name}\")\n",
    "    print(f\"Video URL: {video_url}\")\n",
    "\n",
    "    # Extract the video name from the URL (assuming the URL ends with the video name)\n",
    "    video_name = os.path.basename(video_url)\n",
    "    video_name_without_ext = os.path.splitext(video_name)[0]\n",
    "\n",
    "    auth_key = \"AUTHORIZATION TOKEN\"\n",
    "    translator = deepl.Translator(auth_key)\n",
    "\n",
    "    result = translator.translate_text(object_name, target_lang=\"EN-US\")\n",
    "    classes = [cls.strip() for cls in result.text.split(',')]\n",
    "    print(classes)\n",
    "    model.set_classes(classes)  # 클래스 이름 설정\n",
    "\n",
    "    cap = cv2.VideoCapture(video_url)\n",
    "    if not cap.isOpened():\n",
    "        raise HTTPException(status_code=500, detail=\"Failed to open video URL\")\n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_area = frame_width * frame_height\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    process_fps = 5\n",
    "    frame_interval = int(fps / process_fps)\n",
    "\n",
    "    # 각 클래스별 바운딩 박스 수를 저장할 딕셔너리 초기화\n",
    "    bounding_box_counts = {cls: [] for cls in classes}\n",
    "\n",
    "    # 아웃풋 동영상 경로 설정\n",
    "    output_dir = os.path.join(os.getcwd(), 'output_asset')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    TARGET_VIDEO_PATH = os.path.join(output_dir, f'{video_name_without_ext}_output_video.mp4')\n",
    "\n",
    "    out = cv2.VideoWriter(TARGET_VIDEO_PATH, cv2.VideoWriter_fourcc(*'mp4v'), 20.0, (frame_width, frame_height))\n",
    "\n",
    "    for frame_idx in tqdm(range(frame_count)):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx % frame_interval == 0:\n",
    "            results = model.infer(frame, confidence=0.08)\n",
    "            detections = sv.Detections.from_inference(results).with_nms(threshold=0.1)\n",
    "            detections = detections[(detections.area / frame_area) < 0.5]\n",
    "\n",
    "            # 각 클래스별 바운딩 박스 수를 세기\n",
    "            class_counts = {cls: 0 for cls in classes}\n",
    "            for det in detections:\n",
    "                class_name = det[5]['class_name']  # det의 5번째 요소에서 class_name 가져오기\n",
    "                if class_name in class_counts:\n",
    "                    class_counts[class_name] += 1\n",
    "            \n",
    "            for cls in classes:\n",
    "                bounding_box_counts[cls].append(class_counts[cls])\n",
    "\n",
    "            annotated_frame = frame.copy()\n",
    "            annotated_frame = BOUNDING_BOX_ANNOTATOR.annotate(annotated_frame, detections)\n",
    "            annotated_frame = LABEL_ANNOTATOR.annotate(annotated_frame, detections)\n",
    "            out.write(annotated_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    total_bounding_boxes = sum(sum(counts) for counts in bounding_box_counts.values())\n",
    "\n",
    "    # 객체 수 저장\n",
    "    frame_detections = [(i * frame_interval, {cls: bounding_box_counts[cls][i] for cls in classes}) for i in range(len(bounding_box_counts[classes[0]]))]\n",
    "    with open(f'{video_name_without_ext}_detections.pkl', 'wb') as f:\n",
    "        pickle.dump(frame_detections, f)\n",
    "\n",
    "    # 비디오 파일을 Base64로 인코딩\n",
    "    with open(TARGET_VIDEO_PATH, \"rb\") as video_file:\n",
    "        video_base64 = base64.b64encode(video_file.read()).decode('utf-8')\n",
    "\n",
    "    # 그래프 시각화\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    for cls in classes:\n",
    "        counts_smoothed = gaussian_filter1d(bounding_box_counts[cls], sigma=2)\n",
    "        frames_np = np.arange(len(bounding_box_counts[cls]))\n",
    "        spline = make_interp_spline(frames_np, counts_smoothed, k=3)\n",
    "        frames_smooth = np.linspace(frames_np.min(), frames_np.max(), 500)\n",
    "        counts_smooth = spline(frames_smooth)\n",
    "        ax.plot(frames_smooth, counts_smooth, label=cls, linewidth=3)\n",
    "\n",
    "    threshold = min(min(gaussian_filter1d(bounding_box_counts[cls], sigma=2)) for cls in classes) + 0.5\n",
    "    ax.axhline(y=threshold, color='black', linestyle='--')\n",
    "\n",
    "    # ax.set_title('Object Detection Count per Frame')\n",
    "    # ax.set_xlabel('Frame Index')\n",
    "    # ax.set_ylabel('Count')\n",
    "    ax.legend()\n",
    "    ax.grid(False)\n",
    "\n",
    "    # 그래프를 PNG로 저장\n",
    "    graph_path = os.path.join(output_dir, f'{video_name_without_ext}_result.png')\n",
    "    plt.savefig(graph_path)\n",
    "\n",
    "    # 그래프를 Base64로 인코딩\n",
    "    with open(graph_path, \"rb\") as image_file:\n",
    "        graph_base64 = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    return {\n",
    "        \"total_bounding_boxes\": total_bounding_boxes,\n",
    "        \"graph_data\": graph_base64,\n",
    "        \"video_data\": video_base64,\n",
    "        \"graph_path\": graph_path\n",
    "    }\n",
    "\n",
    "# ngrok 설정 및 FastAPI 서버 실행\n",
    "ngrok.set_auth_token(\"AUTHORIZATION TOKEN\")\n",
    "nest_asyncio.apply()\n",
    "ngrok_tunnel = ngrok.connect(8000)\n",
    "print(\"Public URL:\", ngrok_tunnel.public_url)\n",
    "\n",
    "import uvicorn\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
